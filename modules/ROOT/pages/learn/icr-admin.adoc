= Replication Administration
:page-layout: article
:page-status: {release-status-sgw} -- {release-comments-sgw}
:page-edition: Under Development
:page-role:
:description: Inter-cluster replication (Sync Gateway to Sync Gateway) administration using SG-Replicate protocol

include::partial$_std-hdr-sgw.adoc[]
:topic-group: Inter-cluster Replication
:param-related: {xref-sgw-pg-config-properties} | {xref-sgw-pg-rest-api-admin}
:param-abstract: This content covers the administration aspects of inter-cluster  replication
include::partial$block-abstract.adoc[]

ifeval::["{releaseStatus}" == "gamma"]
[.pane__frame--orange]
.Author's Notes
--
Document relevant aspects of _replication administration_.

Information sources include:

*  https://issues.couchbase.com/browse/DOC-6493
* https://docs.google.com/document/d/13E6JOq8u_AaUd_t8FZEPCAuq7jfkjryecjBQBHE3pG8/edit?ts=5e7cd22f#heading=h.b2gu37hg0ou0
--
endif::[]


== Overview
ifeval::["{releaseStatus}" != "production"]
[.pane__frame--orange]
.Author's Notes
--
CAUTION: CONTENT UNDER DEVELOPMENT

--
endif::[]

// tag::overview[]
Summary of content of admin page.
// end::overview[]



See: https://docs.google.com/document/d/13E6JOq8u_AaUd_t8FZEPCAuq7jfkjryecjBQBHE3pG8/edit?ts=5e7cd22f#heading=h.b2gu37hg0ou0 for content



* configuration
+
The replication  configuration for SG-replicate 2 will now be moved under the database section. The pre-Hydrogen way of configuring replication will be deprecated starting Hydrogen. Refer to upgrade section for specifics on how existing replications will be mapped to new model starting Hydrogen.
*


INCOMPLETE

You can conduct Sync Gateway cluster administration manually should you wish, or circumstances (development environments, production failure or troubleshooting activities) dictate, but in most cases it is likely to be automated. Such automation may be implemented by script, Kubernetes or application server.

Manual::
+
--
Manual operation will typically take place if the cluster is malfunctioning and needs troubleshooting or in demonstration and development environments.
For instance, in the process of debugging why a replication is slow, there would be a need to temporarily stop a replication and subsequently restart when the issue is resolved.  Another case would be if the parameters of the replication need to change.
--

Automated::
+
--
In the case of a decentralized cloud environments managed by an orchestration engine such as K8s, users will likely deploy clusters with a basic configuration. This is because each edge may have different channels and replication requirements.

To handle this, the configuration should be sufficient only to connect to the local cluster and to subsequently initialize replications on a per edge basis.
--

// Remote Configuration::
// A remote configuration facility to manage replications is highly desirable as it would ensure that config changes made to a cluster after launch are persisted on subsequent launches.
// +
// Under current Sync Gateway architecture the only way to do this is to embed the replication in the configuration file, because transient (`adhoc=true`) replications configured using the REST API are not persisted.

// Persisting replications only via config file has practical limitations. For example in cases where a replication is misbehaving causing Sync Gateway to crash (or fail) and must be removed (or updated) so it does not continue to crash (or malfunction) on restart. This may be the case if the replication target changes as a result of an infrastructure change, or filter params change after launch.

// Embedding the replication in config file is also not practical in an automated orchestration environment such as K8s, which will auto restart a failing Sync Gateway with same config file, causing repeating fails on restart .

// Even outside of K8s, restarting a sync gateway will shed any post-launch changes made by the administrator.

// Editing a config file to remove, or update, misconfigured replications means downtime as it  requires taking the Sync Gateway offline for temporary period while the changes are made. In
// an automated environment, the system may auto restart another replica to ensure that system has minimal number of servers running. This experience is not frictionless.

// Customized::
// In lieu of a global cluster-wide admin console for sync gateway (or on a per-node basis for that matter), customers may have to build one on their own. Providing an easy-to-use interface for configuring persistent replications would be highly desirable. Avoids the amount of book keeping that the “admin app” will have to do.


=== REST API Admin capabilities:

Use of `_active_tasks` is deprecated.

Use `_replicate` to administrate replications  (`PUT`, `GET`, `DELETE`).

List persistent and transient replications::
+
--
The list includes replications initiated using configuration or REST APi and can be in any state.
--

Stop an active persistent or transient replication::
+
--
For example to offline an edge cluster without waiting for a long replication to complete. The convenience API means only the `replication_id` parameter is required.
--

Reset a persistent replication::
+
--
This is useful to escape a system state where one or more documents have failed to sync but where resuming from previous synced checkpoint would skip over those documents.
--

Update a persistent continuous replication::
+
--

--

Remove a persistent or transient replication::
+
--
Behavior is unchanged, with exception of a convenience API that required only the `replication_id`.
--

See: {xref-sgw-pg-admin-rest-api}

include::partial$block-related-content-icr.adoc[]